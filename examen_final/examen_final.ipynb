{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T22:04:08.137468Z",
     "start_time": "2025-03-14T22:04:07.971680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n"
   ],
   "id": "c7293f260289057d",
   "outputs": [],
   "execution_count": 141
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "EXAMEN FINAL\n",
    "\n"
   ],
   "id": "644d02261135dfbc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T22:04:08.443173Z",
     "start_time": "2025-03-14T22:04:08.157392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = '../resources/examen_final/wine_quality.csv'  #ruta del data set\n",
    "data_original = pd.read_csv(path, sep=',', ) #se hace la lectura del archivo\n",
    "data_copy = data_original.copy().drop('Unnamed: 0', axis=1) #Se elimina columna innecesaria que solo funciona como indice"
   ],
   "id": "97966273dcfa67fa",
   "outputs": [],
   "execution_count": 142
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "En el anterior paso como se menciona, revisando el data set se encuentra una columna la cual no tiene nombre y no aporta información si no solo cumple la función de indice por lo cual se decide crear una copia del data set original eliminando dicha columna. \n",
    "\n",
    "Se procede a verificar las variables sin dicha columna.\n",
    " \n"
   ],
   "id": "bd75448501fccec8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T22:04:10.137908Z",
     "start_time": "2025-03-14T22:04:10.105718Z"
    }
   },
   "cell_type": "code",
   "source": "data_copy.head(10) #verificación de las columnas ",
   "id": "affdd8b4c01a10b1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "5            7.4              0.66         0.00             1.8      0.075   \n",
       "6            7.9              0.60         0.06             1.6      0.069   \n",
       "7            7.3              0.65         0.00             1.2      0.065   \n",
       "8            7.8              0.58         0.02             2.0      0.073   \n",
       "9            7.5              0.50         0.36             6.1      0.071   \n",
       "\n",
       "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "5                 13.0                  40.0   0.9978  3.51       0.56   \n",
       "6                 15.0                  59.0   0.9964  3.30       0.46   \n",
       "7                 15.0                  21.0   0.9946  3.39       0.47   \n",
       "8                  9.0                  18.0   0.9968  3.36       0.57   \n",
       "9                 17.0                 102.0   0.9978  3.35       0.80   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  \n",
       "5      9.4        5  \n",
       "6      9.4        5  \n",
       "7     10.0        7  \n",
       "8      9.5        7  \n",
       "9     10.5        5  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.069</td>\n",
       "      <td>15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.065</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.073</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.57</td>\n",
       "      <td>9.5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.071</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 143
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Como se puede observar en la tabla anterior, se poseen un conjunto de datos numéricos, no hay la presencia de variables categóricas por lo cual no se requiere hacer ningún tipo de transformación inicial de tipo hot encoder o get dummies \n",
    "\n",
    "Se procede a revisar si hay nulos en los datos"
   ],
   "id": "5e93d6b98762d8df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T22:04:10.297769Z",
     "start_time": "2025-03-14T22:04:10.281824Z"
    }
   },
   "cell_type": "code",
   "source": "print(f'Valores Nulos: \\n{data_copy.isnull().sum()} ') #comando para verificar el total de nulos por cada columna",
   "id": "2669738fafa22486",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores Nulos: \n",
      "fixed_acidity           0\n",
      "volatile_acidity        0\n",
      "citric_acid             0\n",
      "residual_sugar          0\n",
      "chlorides               0\n",
      "free_sulfur_dioxide     0\n",
      "total_sulfur_dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "quality                 0\n",
      "dtype: int64 \n"
     ]
    }
   ],
   "execution_count": 144
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Como se puede evidenciar en la información anterior, no hay la presencia de nulos por ende no es necesario hacer ningún tratamiento en los datos, así que se procede a verificar pesos en memoria para optimizar recursos",
   "id": "c4bf72d0344d627c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T22:04:10.661841Z",
     "start_time": "2025-03-14T22:04:10.635125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Tamaño Datos:  \\n{data_copy.dtypes}') #verificar el tipo o tamaño de los datos\n",
    "print('-----------------')\n",
    "print(f'Uso de memoria: \\n{data_copy.memory_usage(deep= True)}') # mostrar el consumo de memoria por cada columna"
   ],
   "id": "711b2008aeb5e7f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño Datos:  \n",
      "fixed_acidity           float64\n",
      "volatile_acidity        float64\n",
      "citric_acid             float64\n",
      "residual_sugar          float64\n",
      "chlorides               float64\n",
      "free_sulfur_dioxide     float64\n",
      "total_sulfur_dioxide    float64\n",
      "density                 float64\n",
      "pH                      float64\n",
      "sulphates               float64\n",
      "alcohol                 float64\n",
      "quality                   int64\n",
      "dtype: object\n",
      "-----------------\n",
      "Uso de memoria: \n",
      "Index                     128\n",
      "fixed_acidity           51976\n",
      "volatile_acidity        51976\n",
      "citric_acid             51976\n",
      "residual_sugar          51976\n",
      "chlorides               51976\n",
      "free_sulfur_dioxide     51976\n",
      "total_sulfur_dioxide    51976\n",
      "density                 51976\n",
      "pH                      51976\n",
      "sulphates               51976\n",
      "alcohol                 51976\n",
      "quality                 51976\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 145
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Según la información anterior los datos en su mayoría son de tipo Float64 y un Int64 lo cual significa que en memoria se est+an implementando 51976 de almacenamiento lo cual puede significar que al momento de entrenar los modelos o hacer la validación cruzada este se va a demorar más tiempo\n",
    "\n",
    "Ahora se hace validación del tamaño para reducir almacenamiento para optimizar rendimiento"
   ],
   "id": "a50d3375187e83d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T22:04:10.853086Z",
     "start_time": "2025-03-14T22:04:10.843788Z"
    }
   },
   "cell_type": "code",
   "source": "print(data_copy.max()) #busqueda de los valores más grandes",
   "id": "426d027253534418",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed_acidity            15.90000\n",
      "volatile_acidity          1.58000\n",
      "citric_acid               1.66000\n",
      "residual_sugar           65.80000\n",
      "chlorides                 0.61100\n",
      "free_sulfur_dioxide     289.00000\n",
      "total_sulfur_dioxide    440.00000\n",
      "density                   1.03898\n",
      "pH                        4.01000\n",
      "sulphates                 2.00000\n",
      "alcohol                  14.90000\n",
      "quality                   9.00000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 146
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Se detecta que realmente no es necesario usar datos de tipo Float64 por ende ahora vamos a reducir su tamaño a la mitad",
   "id": "237b1fd92bfa017c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T22:04:10.955466Z",
     "start_time": "2025-03-14T22:04:10.919321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_copy_resized = data_copy.astype({\n",
    "                'fixed_acidity': 'float32',\n",
    "                'volatile_acidity': 'float32',\n",
    "                'citric_acid': 'float32',\n",
    "                'residual_sugar': 'float32',\n",
    "                'chlorides': 'float32',\n",
    "                'free_sulfur_dioxide': 'float32',\n",
    "                'total_sulfur_dioxide': 'float32',\n",
    "                'density': 'float32',\n",
    "                'pH': 'float32',\n",
    "                'sulphates': 'float32',\n",
    "                'alcohol': 'float32',\n",
    "                'quality': 'int8'})  #se hace la asignación de los nuevos tamaños conservando el tipo\n",
    "\n",
    "tabla = list(zip(data_copy.columns,data_copy.memory_usage(deep= True), data_copy_resized.memory_usage(deep = True)))#creamos tabla para hacer comparativa de consumos de memoria\n",
    "tabla = pd.DataFrame(tabla, columns=['columnas', 'peso original en memoria', 'peso ajustado en memoria'])\n",
    "print(tabla)"
   ],
   "id": "e66dc3b9dd9c070c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                columnas  peso original en memoria  peso ajustado en memoria\n",
      "0          fixed_acidity                       128                       128\n",
      "1       volatile_acidity                     51976                     25988\n",
      "2            citric_acid                     51976                     25988\n",
      "3         residual_sugar                     51976                     25988\n",
      "4              chlorides                     51976                     25988\n",
      "5    free_sulfur_dioxide                     51976                     25988\n",
      "6   total_sulfur_dioxide                     51976                     25988\n",
      "7                density                     51976                     25988\n",
      "8                     pH                     51976                     25988\n",
      "9              sulphates                     51976                     25988\n",
      "10               alcohol                     51976                     25988\n",
      "11               quality                     51976                     25988\n"
     ]
    }
   ],
   "execution_count": 147
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Como se evidencia en la tabla anterior se ha reducido el peso en memoria a la mitad de las variables que van a ser implementadas esto permite optimizar los tiempos de entrenamiento de los modelos, permitiendo crear mayor cantidad de modelos o validaciones cruzadas sin sobre exigir al dispositivo donde se entrene.\n",
    "\n",
    "Ahora se va a encontrar con un proceso que se encuentra comentado el cual más adelante se va a dar una justificación de porque se encuentra así. Sin embargo, la siguiente celda se enfoca en la búsqueda de valores duplicados, originalmente se encuentra con 1179 datos duplicados, luego de hallarlos realiza una búsqueda para mirar si estos duplicados tienen o no etiquetas diferentes, es decir, si tienen exactamente las mismas características, pero etiquetas distintas puede significar un error en los datos, alguna muestra mal tomada o un error humano, por ende si el total de duplicados con etiquetas diferentes es diferente de 0 se refiere a dicho error. \n",
    "Para este caso responde 0 por lo cual se pueden eliminar los duplicados, sin embargo, y como se mencionó antes se optó al final por no eliminarlos, más adelante se dará la justificación, pero, si se desea puede descomentar la celda y correr todo el proyecto para comparar al final los accuracy entre set de datos con datos duplicados y sin duplicados."
   ],
   "id": "7106094bd2eb6eb6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T22:04:11.041116Z",
     "start_time": "2025-03-14T22:04:11.018385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print(f'Dimensionalidad Original: {data_copy.shape} ') #imprimir las dimensionalidades originales\n",
    "# print('-----------------')\n",
    "# print(f'Datos duplicados: {data_copy_resized.duplicated().sum()}') #Mostrar el total de datos duplicados\n",
    "# \n",
    "# duplicates = data_copy_resized[data_copy_resized.duplicated(keep=False)] #Almacena los duplicados contando la primera vez que aparece no como duplicated que ignora la primera\n",
    "# print(f\"Total de filas duplicadas: {len(duplicates)}\") #Imprimimos en pantalla el total de registros duplicados\n",
    "# different_labels = duplicates.groupby(data_copy_resized.columns[:-1].tolist())[\"quality\"].nunique() #Guarda los registros duplicados agrupando por la columna quality\n",
    "# \n",
    "# # Filtramos los casos donde haya más de una etiqueta distinta\n",
    "# conflicting_duplicates = different_labels[different_labels > 1] #Aplicamos filtro para saber si hay duplicados con etiquetas diferentes \n",
    "# print(f\"Total de duplicados con etiquetas diferentes: {len(conflicting_duplicates)}\") \"imprimimos en pantalla\n",
    "# \n",
    "# data_copy_resized = data_copy_resized.drop_duplicates() #Hacemos drop de los datos duplicados\n",
    "# print(f'----------'\n",
    "#       f'\\nDatos duplicados finales: {data_copy_resized.duplicated().sum()}' #imprimimmos los duplicados finales, debería ser 0\n",
    "#       f'\\n----------'\n",
    "#       f'\\nDimensiones finales: {data_copy_resized.shape}') #Mostramos las dimensiones finales\n"
   ],
   "id": "8940d6f28419fa41",
   "outputs": [],
   "execution_count": 148
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ahora vamos a revisar si hay desbalance de entre las clases por medio de un gráfico",
   "id": "cae882d35b3dbb06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T22:04:11.343818Z",
     "start_time": "2025-03-14T22:04:11.148247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "data_copy_resized['quality'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.xlabel(\"Quality\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribución de etiquetas después de eliminar duplicados\")\n",
    "plt.show()\n",
    "\n",
    "class_counts = data_copy_resized[\"quality\"].value_counts().sort_index() #contamos la cantidad de registros por cada clase\n",
    "# Mostrar el conteo en la consola\n",
    "print(\"Total de registros por clase:\")\n",
    "print(class_counts)"
   ],
   "id": "efdb02df75c7d70f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros por clase:\n",
      "quality\n",
      "3      30\n",
      "4     216\n",
      "5    2138\n",
      "6    2836\n",
      "7    1079\n",
      "8     193\n",
      "9       5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 149
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Como podemos observar en las tablas anteriores podemos concluir lo siguiente:\n",
    "- Hay un desbalance de clases bastante fuerte, ya que las que tienen más representación en el conjunto de datos son la 5 con 2138 registros, 6 con 2836 y 7 con 1079\n",
    "- Según la documentación las clasificaciones pueden ir desde 1 a 10, pero no hay registros con clasificación 1, 2 o 10, lo cual va a volver demasiado complicado llegar a clasificar bajo estas etiquetas\n",
    "- Este desbalance de clases va a significar una complicación para el aprendizaje del modelo debido a que este va a tender a tener sesgos entre las clases mayoritarias y minoritarias\n",
    "\n",
    "Con este primer acercamiento comenzamos separando el conjunto de entrenamiento y test en una proporción de 80 - 20 siendo entrenamiento y test respectivamente"
   ],
   "id": "ed3dad7289785d80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T22:04:11.505531Z",
     "start_time": "2025-03-14T22:04:11.455805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = data_copy_resized.drop(columns = [\"quality\"]) #creamos variable con las variables independientes, drop de la variable objetivo\n",
    "y = data_copy_resized[\"quality\"] #creamos variable y que sería la objetivo unicamente\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify= y, random_state= 42) #separación de conjunto prueba y test"
   ],
   "id": "cd4896f6fd134c28",
   "outputs": [],
   "execution_count": 150
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Una vez separado el conjunto de datos, se procede a crear un balanceador para poder equilibrar las clases, en este caso, se decide implementar un balanceador de SMOTE con estrategia \"not Majority\" para evitar que favorezca la clase mayoritaria y se centre en las menores, adicionalmente, para este ejercicio se va a optar por hacer dos versiones:\n",
    "- Primera version con el conjunto de datos balanceados \n",
    "- Segunda version con el conjunto de datos SIN balancear\n",
    "\n",
    "Esto con el fin de analizar que metodología obtiene mejores resultados"
   ],
   "id": "a8c22b8a67e6e0e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T22:04:11.801476Z",
     "start_time": "2025-03-14T22:04:11.518557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "smote = SMOTE(sampling_strategy= \"not majority\", k_neighbors= 3, random_state= 42) #creación del balanceador SMOTE \n",
    "X_train_sampled, y_train_sampled = smote.fit_resample(X_train, y_train) #creación de los nuevos conjuntos balanceados\n",
    "print(y_train_sampled.value_counts()) #mostramos los nuevos valores\n"
   ],
   "id": "daf32c26f5e3b6c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality\n",
      "5    2269\n",
      "7    2269\n",
      "6    2269\n",
      "8    2269\n",
      "3    2269\n",
      "4    2269\n",
      "9    2269\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 151
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Una vez tenemos los dos conjuntos de datos (balanceados, sin balancear) se procede a evaluar la estrategía para abordar la situación problema. \n",
    "\n",
    "Para este problema se van a implementar tres diferentes modelos a los cuales se les va a hacer una búsqueda de hiperparámetros, estos modelos son:\n",
    "- RandomForest\n",
    "- XGBoost\n",
    "- SVM \n",
    "\n",
    "Partiendo de esta idea empezamos creando las listas de parámetros para cada uno "
   ],
   "id": "f84e672e31cf900d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T22:04:11.934781Z",
     "start_time": "2025-03-14T22:04:11.913804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#HIPERPARAMETROS PARA BUSQUEDA\n",
    "\n",
    "#Random Forest\n",
    "param_list_rf = {\n",
    "    \"model__n_estimators\": randint(50, 150),\n",
    "    \"model__max_depth\": randint(3, 20),\n",
    "    \"model__class_weight\": [\"balanced\"],\n",
    "    \"model__min_samples_split\": randint(2, 15)\n",
    "}\n",
    "#XGBoost\n",
    "param_list_xbg = {\n",
    "    \"model__n_estimators\": randint(50, 200),\n",
    "    \"model__max_depth\": randint(3, 5),\n",
    "    \"model__learning_rate\": uniform(0.01, 0.2),\n",
    "    \"model__reg_alpha\": [0, 0.1, 0.5, 0.7],  \n",
    "    \"model__reg_lambda\": [0, 0.1, 0.5, 0.7]\n",
    "}\n",
    "#SVM\n",
    "param_list_svm = {\n",
    "    \"model__C\": uniform(0.1, 10),\n",
    "    \"model__gamma\": [\"scale\"],\n",
    "    \"model__class_weight\": [\"balanced\", None],\n",
    "    \"model__kernel\": [\"linear\", \"rbf\"]\n",
    "}"
   ],
   "id": "c3fa15cf66c35712",
   "outputs": [],
   "execution_count": 152
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Ahora se procede a crear el pipeline de cada uno para esto se tiene en cuenta lo siguiente:\n",
    "- RandomForest: se implementa RandomForestClassifier como clasificador\n",
    "- XGBoost: Este necesita una normalización, después de varias pruebas se opta por un RobustScaler() para controlar de manera más resistente los outliers dado el desbalance, también se utiliza un XGBClassifier con eval_metric \"mlogloss\"\n",
    "- SVM: Este también necesita una normalización y después de pruebas se opta también por un RobustScaler() por las mismas razones, para este caso se usa un SVC con kernel linear y C 1.0 para tratar de evitar overfitting"
   ],
   "id": "3e0ba0ff48d783fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T22:04:11.950515Z",
     "start_time": "2025-03-14T22:04:11.940222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#DEFINICION DE PIPELINES PARA BUSQUEDA\n",
    "#RandomForest\n",
    "rf_pipeline = Pipeline([\n",
    "    (\"model\", RandomForestClassifier(random_state = 42))\n",
    "])\n",
    "#XGBoost\n",
    "xgb_pipeline = Pipeline([\n",
    "    (\"scaler\", RobustScaler()),\n",
    "    (\"model\", XGBClassifier(eval_metric = \"mlogloss\"))\n",
    "])\n",
    "#SVM\n",
    "svm_pipeline = Pipeline([\n",
    "    (\"scaler\", RobustScaler()),\n",
    "    (\"model\", SVC(kernel= \"linear\",C = 1.0, probability= True))\n",
    "])"
   ],
   "id": "33cecd6a37d5bb6e",
   "outputs": [],
   "execution_count": 153
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Dado que se tienen dos conjuntos de datos, balanceados, desbalanceados y se quiere hacer una validación cruzada para encontrar se decide crear una función que recibe por parametro de entrada lo siguiente:\n",
    "- pipeline: se refiere al pipeline del modelo a ejecutar\n",
    "- param_list: son los parametros del modelo al que se le va a hacer la validación cruzada\n",
    "- X: conjunto de entrenamiento, este puede ser balanceado o sin balancear\n",
    "- y: etiquetas de entrenamiento, este puede ser balanceado o sin balancear\n",
    "- name: el nombre del modelo el cual se le va a hacer la validación cruzada y posterior entrenamiento\n",
    "\n",
    "Adicionalmente, se va a encontrar una condición la cual se ejecuta únicamente para el modelo XGBoost el cual organiza el rango de las etiquetas de 0 a 9, ya que este es un modelo iterativo y al no tener registros con clasificaciones 1 o 2 recibe solamente de 3 a 9 lo que lo hace fallar"
   ],
   "id": "7459173021307cd8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T22:04:12.013783Z",
     "start_time": "2025-03-14T22:04:11.998625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def search_best_params(pipeline, param_list, X, y, name):\n",
    "    global class_mapping\n",
    "    if name in[\"XGBoost Sampled Train\", \"XGBoost Train\"]:\n",
    "        unique_classes = np.sort(y.unique())  \n",
    "        class_mapping = {old_label: new_label for new_label, old_label in enumerate(unique_classes)}\n",
    "        y = y.map(class_mapping)\n",
    "     \n",
    "    search = RandomizedSearchCV(pipeline, param_list, n_iter = 10, cv = 3, scoring=\"accuracy\", random_state=42, n_jobs= -1) #se hace la validación cruzada dependiendo el modelo\n",
    "    search.fit(X,y) #Ejecutamos el entrenamiento\n",
    "    print(f\"\\nMejores hiperparametros para {name}:\")\n",
    "    print(search.best_params_) #imprimimos los mejores parámetros\n",
    "    best_score = search.best_score_\n",
    "    print(f\"Mejor Accuracy: {search.best_score_:.4f}\") #imprimimos el mejor accuracy encontrado por la validación cruzada \n",
    "    print(f\"Reporte de clasificacion para modelo {name}: \\n{classification_report(search.predict(X), y, digits= 4, zero_division=0)}\") #mostramos un reporte que permite evaluar la precision por etiqueta, recall, f1 y support\n",
    "\n",
    "    return search.best_estimator_, best_score, name, class_mapping if name in [\"XGBoost Sampled Train\", \"XGBoost Train\"] else None"
   ],
   "id": "31dede32d111dd59",
   "outputs": [],
   "execution_count": 154
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Una vez definida dicha función, se procede a hacer los entrenamientos e inspección de cada modelo con balance y sus respectivos parámetros, este guarda diferentes valores en diferentes variables las cuales son:\n",
    "- Primera: guarda el mejor estimador\n",
    "- Segundo: guarda el mejor score\n",
    "- Tercero: guarda el nombre del modelo el cual ejecutó la función\n",
    "- Cuarto: este aplica únicamente para XGboost, ya que necesita un mapeo de las clases para poder visualizarlo bien dado el ajuste de las etiquetas\n",
    "\n",
    "Tenga en cuenta que son tres modelos con balance por ende la función es invocada tres veces "
   ],
   "id": "9b90af2ab276803c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T22:06:32.256399Z",
     "start_time": "2025-03-14T22:04:12.072827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n Evaluando modelos en datos Sampled: \")\n",
    "best_rf_resampled, best_score_rf_sampled, name_rf_sampled, _ = search_best_params(rf_pipeline, param_list_rf, X_train_sampled, y_train_sampled, \"Random Forest Sampled Train\")\n",
    "best_xgb_resampled, best_score_xgb_sampled, name_xgb_sampled, xgb_class_mapping_resample = search_best_params(xgb_pipeline, param_list_xbg, X_train_sampled, y_train_sampled, \"XGBoost Sampled Train\")\n",
    "best_svm_resampled, best_score_svm_sampled, name_svm_sampled, _ = search_best_params(svm_pipeline, param_list_svm, X_train_sampled, y_train_sampled, \"SVM Sampled Train\")\n"
   ],
   "id": "11c3a9055fde174",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluando modelos en datos Sampled: \n",
      "\n",
      "Mejores hiperparametros para Random Forest Sampled Train:\n",
      "{'model__class_weight': 'balanced', 'model__max_depth': 17, 'model__min_samples_split': 12, 'model__n_estimators': 121}\n",
      "Mejor Accuracy: 0.8564\n",
      "Reporte de clasificacion para modelo Random Forest Sampled Train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3     1.0000    0.9996    0.9998      2270\n",
      "           4     0.9969    0.9780    0.9873      2313\n",
      "           5     0.9471    0.9235    0.9352      2327\n",
      "           6     0.9039    0.9571    0.9297      2143\n",
      "           7     0.9758    0.9702    0.9730      2282\n",
      "           8     0.9991    0.9947    0.9969      2279\n",
      "           9     1.0000    1.0000    1.0000      2269\n",
      "\n",
      "    accuracy                         0.9747     15883\n",
      "   macro avg     0.9747    0.9747    0.9746     15883\n",
      "weighted avg     0.9752    0.9747    0.9748     15883\n",
      "\n",
      "\n",
      "Mejores hiperparametros para XGBoost Sampled Train:\n",
      "{'model__learning_rate': np.float64(0.17648852816008437), 'model__max_depth': 4, 'model__n_estimators': 179, 'model__reg_alpha': 0.7, 'model__reg_lambda': 0.7}\n",
      "Mejor Accuracy: 0.8301\n",
      "Reporte de clasificacion para modelo XGBoost Sampled Train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9996    0.9956    0.9976      2278\n",
      "           1     0.9828    0.9445    0.9633      2361\n",
      "           2     0.8356    0.8548    0.8451      2218\n",
      "           3     0.7823    0.8396    0.8099      2114\n",
      "           4     0.9123    0.8973    0.9047      2307\n",
      "           5     0.9868    0.9585    0.9724      2336\n",
      "           6     1.0000    1.0000    1.0000      2269\n",
      "\n",
      "    accuracy                         0.9285     15883\n",
      "   macro avg     0.9285    0.9272    0.9276     15883\n",
      "weighted avg     0.9308    0.9285    0.9294     15883\n",
      "\n",
      "\n",
      "Mejores hiperparametros para SVM Sampled Train:\n",
      "{'model__C': np.float64(8.424426408004217), 'model__class_weight': None, 'model__gamma': 'scale', 'model__kernel': 'rbf'}\n",
      "Mejor Accuracy: 0.7779\n",
      "Reporte de clasificacion para modelo SVM Sampled Train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3     1.0000    0.9801    0.9900      2315\n",
      "           4     0.9467    0.8342    0.8869      2575\n",
      "           5     0.7149    0.7454    0.7298      2176\n",
      "           6     0.5090    0.7030    0.5905      1643\n",
      "           7     0.7466    0.7006    0.7229      2418\n",
      "           8     0.8872    0.8094    0.8465      2487\n",
      "           9     1.0000    1.0000    1.0000      2269\n",
      "\n",
      "    accuracy                         0.8292     15883\n",
      "   macro avg     0.8292    0.8247    0.8238     15883\n",
      "weighted avg     0.8453    0.8292    0.8346     15883\n",
      "\n"
     ]
    }
   ],
   "execution_count": 155
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "En los valores anteriores se pueden observar los mejores parámetros, el mejor accuracy y un reporte basádo en los datos de entrenamiento, a primera instancia aparentemente este entrenamiento con los datos balanceados tiene unos resultados bastante positivos dado que tenemos accuracy mayores a 73% hasta 97%. \n",
    "\n",
    "Ahora se procede a hacer el mismo ejercicio pero ahora invocando la función con los datos sin balancear, es decir los mismos tres modelos pero con datos de entrenamiento sin balancear."
   ],
   "id": "e50dee7b04c39bcd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T22:06:56.260935Z",
     "start_time": "2025-03-14T22:06:32.433777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n Evaluando modelos en datos sin Sampled: \")\n",
    "best_rf, best_score_rf, name_rf, _ = search_best_params(rf_pipeline, param_list_rf, X_train, y_train, \"Random Forest Train \")\n",
    "best_xgb, best_score_xgb, name_xgb, xgb_class_mapping = search_best_params(xgb_pipeline, param_list_xbg, X_train, y_train, \"XGBoost Train\")\n",
    "best_svm, best_score_svm, name_svm,_ = search_best_params(svm_pipeline, param_list_svm, X_train, y_train, \"SVM Train\")"
   ],
   "id": "343554d7765fa545",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluando modelos en datos sin Sampled: \n",
      "\n",
      "Mejores hiperparametros para Random Forest Train :\n",
      "{'model__class_weight': 'balanced', 'model__max_depth': 17, 'model__min_samples_split': 12, 'model__n_estimators': 121}\n",
      "Mejor Accuracy: 0.6217\n",
      "Reporte de clasificacion para modelo Random Forest Train : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3     1.0000    0.9231    0.9600        26\n",
      "           4     1.0000    0.9105    0.9532       190\n",
      "           5     0.9117    0.8878    0.8996      1756\n",
      "           6     0.8726    0.9429    0.9064      2100\n",
      "           7     0.9710    0.8784    0.9224       954\n",
      "           8     1.0000    0.9222    0.9595       167\n",
      "           9     1.0000    1.0000    1.0000         4\n",
      "\n",
      "    accuracy                         0.9105      5197\n",
      "   macro avg     0.9651    0.9235    0.9430      5197\n",
      "weighted avg     0.9134    0.9105    0.9108      5197\n",
      "\n",
      "\n",
      "Mejores hiperparametros para XGBoost Train:\n",
      "{'model__learning_rate': np.float64(0.17648852816008437), 'model__max_depth': 4, 'model__n_estimators': 179, 'model__reg_alpha': 0.7, 'model__reg_lambda': 0.7}\n",
      "Mejor Accuracy: 0.6142\n",
      "Reporte de clasificacion para modelo XGBoost Train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        24\n",
      "           1     0.8208    0.9930    0.8987       143\n",
      "           2     0.8795    0.8837    0.8816      1702\n",
      "           3     0.9141    0.8510    0.8814      2437\n",
      "           4     0.8076    0.9306    0.8648       749\n",
      "           5     0.9026    1.0000    0.9488       139\n",
      "           6     0.7500    1.0000    0.8571         3\n",
      "\n",
      "    accuracy                         0.8819      5197\n",
      "   macro avg     0.8678    0.9512    0.9046      5197\n",
      "weighted avg     0.8848    0.8819    0.8819      5197\n",
      "\n",
      "\n",
      "Mejores hiperparametros para SVM Train:\n",
      "{'model__C': np.float64(8.424426408004217), 'model__class_weight': None, 'model__gamma': 'scale', 'model__kernel': 'rbf'}\n",
      "Mejor Accuracy: 0.5796\n",
      "Reporte de clasificacion para modelo SVM Train: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3     0.5833    1.0000    0.7368        14\n",
      "           4     0.2312    0.9091    0.3687        44\n",
      "           5     0.7456    0.7282    0.7368      1751\n",
      "           6     0.8030    0.6386    0.7114      2853\n",
      "           7     0.4195    0.6962    0.5235       520\n",
      "           8     0.0909    0.9333    0.1657        15\n",
      "           9     0.0000    0.0000    0.0000         0\n",
      "\n",
      "    accuracy                         0.6787      5197\n",
      "   macro avg     0.4105    0.7008    0.4633      5197\n",
      "weighted avg     0.7378    0.6787    0.6968      5197\n",
      "\n"
     ]
    }
   ],
   "execution_count": 156
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Como podemos observar los accuracy para los modelos desbalanceados son significativamente menores, ya que están entre 57% y 62% lo cual indicaría que los modelos no son tan eficientes a comparación de los modelos con datos balanceados, este tiende a fallar más en clases minoritarias mientras que con clases balanceadas este identifica casi todas sin problema\n",
    "\n",
    "Ahora procedemos a hacer la evaluación de los modelos entrenados previamente con el conjunto test, para este caso se opta por crear una funcion que recibe:\n",
    "- model: mejor modelo entrenado\n",
    "- X_test: datos de prueba\n",
    "- y_test: etiquetas de test para comparar después\n",
    "- class_mapping: solo aplica para XGBoost porque tiene que hacer el proceso inverso de las etiquetas para dejarlas como originalmente estaban\n",
    "\n",
    "Adicionalmente, se va a encontrar con una condicional que como se mencionó anteriormente solo aplica para XGBoost, ya que aplica el proceso inverso a las etiquetas.\n",
    "Finalmente, este hace las predicciones, muestra un reporte con los accuracy, f1, recall y support y devuelve dos variables:\n",
    "- name: nombre del modelo evaluado\n",
    "- acc: se refiere al accuracy logrado\n",
    "\n",
    "Estas dos se almacenan para más adelante comparar con el set de prueba  "
   ],
   "id": "95923c91bbc33cbc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T22:06:56.340360Z",
     "start_time": "2025-03-14T22:06:56.324550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_model(model, X_test, y_test, name, class_mapping = None):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    if class_mapping:\n",
    "        reverse_mapping = {v: k for k, v in class_mapping.items()}\n",
    "        y_pred = np.vectorize(reverse_mapping.get)(y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Reporte de clasificacion para modelo {name}: \\n{classification_report(y_test, y_pred, digits= 4, zero_division=0)}\")\n",
    "    return name, acc"
   ],
   "id": "7b8fcfa0728d5e3b",
   "outputs": [],
   "execution_count": 157
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ejecutamos las pruebas por cada uno de los modelos preentrenados, pasando por parametro sus respectivos valores y el conjunto de test",
   "id": "a6c4d9883a1754f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T22:06:57.058706Z",
     "start_time": "2025-03-14T22:06:56.399103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_test = []\n",
    "results_test.append(evaluate_model(best_rf_resampled, X_test, y_test, \"random forest sampled\"))\n",
    "results_test.append(evaluate_model(best_xgb_resampled, X_test, y_test, \"XGBoost sampled\", xgb_class_mapping_resample))\n",
    "results_test.append(evaluate_model(best_svm_resampled, X_test, y_test, \"SVM Sampled\"))"
   ],
   "id": "a72eac0aa51775b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificacion para modelo random forest sampled: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3     0.0000    0.0000    0.0000         6\n",
      "           4     0.2031    0.3023    0.2430        43\n",
      "           5     0.6682    0.6729    0.6705       428\n",
      "           6     0.7050    0.5732    0.6323       567\n",
      "           7     0.5086    0.6852    0.5838       216\n",
      "           8     0.3333    0.4103    0.3678        39\n",
      "           9     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.6077      1300\n",
      "   macro avg     0.3455    0.3777    0.3568      1300\n",
      "weighted avg     0.6287    0.6077    0.6126      1300\n",
      "\n",
      "Reporte de clasificacion para modelo XGBoost sampled: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3     0.0000    0.0000    0.0000         6\n",
      "           4     0.1714    0.2791    0.2124        43\n",
      "           5     0.6533    0.6075    0.6295       428\n",
      "           6     0.6378    0.5714    0.6028       567\n",
      "           7     0.5000    0.5741    0.5345       216\n",
      "           8     0.3103    0.4615    0.3711        39\n",
      "           9     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.5677      1300\n",
      "   macro avg     0.3247    0.3562    0.3358      1300\n",
      "weighted avg     0.5913    0.5677    0.5771      1300\n",
      "\n",
      "Reporte de clasificacion para modelo SVM Sampled: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3     0.0909    0.1667    0.1176         6\n",
      "           4     0.1327    0.3488    0.1923        43\n",
      "           5     0.6111    0.5911    0.6010       428\n",
      "           6     0.6237    0.4092    0.4941       567\n",
      "           7     0.4508    0.5509    0.4958       216\n",
      "           8     0.1905    0.6154    0.2909        39\n",
      "           9     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.4954      1300\n",
      "   macro avg     0.3000    0.3832    0.3131      1300\n",
      "weighted avg     0.5586    0.4954    0.5114      1300\n",
      "\n"
     ]
    }
   ],
   "execution_count": 158
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Como puede observar, la prueba Test para el modelo preentrenado con datos balanceados presenta una caída significativa en su accuracy, ya que está entre 49% y 60%, más adelante se comparan todos, pero esto es un primer acercamiento sobre el comportamiento de los modelos balanceados.\n",
    "\n",
    "Procedemos ahora a hacer lo mismo para los modelos preentrenados con datos NO balanceados."
   ],
   "id": "894bca7a5d64a1c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T22:06:57.453323Z",
     "start_time": "2025-03-14T22:06:57.111036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_test.append(evaluate_model(best_rf, X_test, y_test, \"random forest\"))\n",
    "results_test.append(evaluate_model(best_xgb, X_test, y_test, \"XGBoost\",  xgb_class_mapping))\n",
    "results_test.append(evaluate_model(best_svm, X_test, y_test, \"SVM\"))"
   ],
   "id": "5d1ebc671f7eab4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificacion para modelo random forest: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3     0.0000    0.0000    0.0000         6\n",
      "           4     0.2667    0.1860    0.2192        43\n",
      "           5     0.6726    0.7009    0.6865       428\n",
      "           6     0.6705    0.6102    0.6390       567\n",
      "           7     0.5197    0.6713    0.5859       216\n",
      "           8     0.5556    0.3846    0.4545        39\n",
      "           9     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.6262      1300\n",
      "   macro avg     0.3836    0.3647    0.3693      1300\n",
      "weighted avg     0.6258    0.6262    0.6229      1300\n",
      "\n",
      "Reporte de clasificacion para modelo XGBoost: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3     0.0000    0.0000    0.0000         6\n",
      "           4     0.2857    0.0930    0.1404        43\n",
      "           5     0.6944    0.6636    0.6786       428\n",
      "           6     0.6263    0.7478    0.6817       567\n",
      "           7     0.6304    0.5370    0.5800       216\n",
      "           8     0.8750    0.3590    0.5091        39\n",
      "           9     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.6477      1300\n",
      "   macro avg     0.4445    0.3429    0.3700      1300\n",
      "weighted avg     0.6422    0.6477    0.6370      1300\n",
      "\n",
      "Reporte de clasificacion para modelo SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3     0.0000    0.0000    0.0000         6\n",
      "           4     0.1111    0.0233    0.0385        43\n",
      "           5     0.6353    0.6308    0.6331       428\n",
      "           6     0.5742    0.7231    0.6401       567\n",
      "           7     0.5533    0.3843    0.4536       216\n",
      "           8     0.0000    0.0000    0.0000        39\n",
      "           9     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.5877      1300\n",
      "   macro avg     0.2677    0.2516    0.2522      1300\n",
      "weighted avg     0.5552    0.5877    0.5642      1300\n",
      "\n"
     ]
    }
   ],
   "execution_count": 159
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Como podemos observar en este caso los valores de los accuracy tienden a mantenerse, si bien varían un poco este permanece entre 58% y 64% incluso se puede notar que hubo un caso donde se desempeñó mejor en test que en entrenamiento, pero más adelante se mostrará la comparativa entre test y entrenamiento, pero esto nos da un primer indicio frente al comportamiento de los modelos no balanceados\n",
    "\n",
    "Ahora extraemos todos los accuracy tanto balanceados como desbalanceados y se unen en dos grupos los cuales son Test y entrenamiento esto con el fin de sacar conclusiones de cada modelo"
   ],
   "id": "24c76c562826144d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T22:26:18.426873Z",
     "start_time": "2025-03-14T22:26:18.396420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_results = pd.DataFrame(results_test, columns = [\"modelo\", \"accuracy\"])\n",
    "df_results = df_results.sort_values(by = \"accuracy\", ascending=False).reset_index(drop= True)\n",
    "print(f\"Comparacion de Accuracy entre Modelos en Test: \\n{df_results}\")\n",
    "results_train = []\n",
    "results_train.append((name_rf, best_score_rf))\n",
    "results_train.append((name_xgb, best_score_xgb))\n",
    "results_train.append((name_svm, best_score_svm))\n",
    "results_train.append((name_rf_sampled, best_score_rf_sampled))\n",
    "results_train.append((name_xgb_sampled, best_score_xgb_sampled))\n",
    "results_train.append((name_svm_sampled, best_score_svm_sampled))\n",
    "df_results_train = pd.DataFrame(results_train, columns = [\"modelo\", \"accuracy\"])\n",
    "df_results_train = df_results_train.sort_values(by = \"accuracy\", ascending=False).reset_index(drop= True)\n",
    "print(f\"Comparacion de Accuracy entre Modelos en Train: \\n{df_results_train}\")"
   ],
   "id": "92f49010f4612d8d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparacion de Accuracy entre Modelos en Test: \n",
      "                  modelo  accuracy\n",
      "0                XGBoost  0.647692\n",
      "1          random forest  0.626154\n",
      "2  random forest sampled  0.607692\n",
      "3                    SVM  0.587692\n",
      "4        XGBoost sampled  0.567692\n",
      "5            SVM Sampled  0.495385\n",
      "Comparacion de Accuracy entre Modelos en Train: \n",
      "                        modelo  accuracy\n",
      "0  Random Forest Sampled Train  0.856388\n",
      "1        XGBoost Sampled Train  0.830072\n",
      "2            SVM Sampled Train  0.777877\n",
      "3         Random Forest Train   0.621709\n",
      "4                XGBoost Train  0.614204\n",
      "5                    SVM Train  0.579567\n"
     ]
    }
   ],
   "execution_count": 163
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "CONCLUSIONES\n",
    "- El mejor modelo para este caso es el modelo de XGBoost el cual muestra un accuracy de 64% en el conjunto de test y un 61% en el conjunto de prueba\n",
    "- los modelos con el balanceo de datos muestran un excelente desempeño en entrenamiento, pero una baja bastante significativa en el conjunto de test (aproximadamente entre 20 a 40% menos), esto indica que hay un sobre entrenamiento en los modelos preentrenados con datos balanceados, esto se puede deber a que el desbalance al ser tan grande, generar datos sintéticos se vuelve contraproducente para el modelo, pues este no es capar de generalizar de manera efectiva.\n",
    "- Los modelos sin el balanceo de datos pese a tener un menor desempeño en entrenamiento, muestran una mayor consistencia e incluso desempeño al momento de hacer predicciones esto demuestra que no hay un sobre entrenamiento lo cual da mayor confiabilidad frente al modelo y sus resultados.\n",
    "- Los modelos sin balanceo son muy buenos para detectar clases mayoritarias como 5, 6 o 7, sin embargo, no son tan efectivas para las demás, por otro lado, este sesgo no fue posible de evitar dado que el desbalance de los datos era bastante contundente luego para el modelo lograr hallar un patron para identificar dichas clases era mucho más complicado que para las clases mayoritarias, pero aun así su capacidad de generalizar es muy buena, pues concuerdan los dos conjuntos en sus porcentajes.\n",
    "- Al final se decide no eliminar los datos duplicados porque si bien estos datos pueden generar problemas al momento de un aprendizaje para este caso en específico eliminarlos afectaban clases minoritarias haciendo que su generalización disminuyera aún más, incluyendo la precision y aumentando el sesgo entre las clases con mayor cantidad de registros frente a las que no, y este impacto se evidenciaba tanto para los datos balanceados como sin balancear, ambos su rendimiento disminuía significativamente.\n",
    "- En este caso los datos duplicados podrían ayudar a una regularización implícita dado que XGBoost y SVM son sensibles al número de ejemplos por clase, entonces estos duplicados pudieron ayudar a suavizar fronteras de decisión\n",
    "- de manera general se sabe que el modelo a futuro necesitará reentrenarse para poder mejorar la clasificación para clases minoritarias, actualmente tiene 64% de precision y es efectivo para las clases 5, 6 y 7, pero para poder ampliar la clasificación y mejorarlo se necesita una mayor cantidad de registros con las demás etiquetas para poder ampliar la capacidad del modelo para identificar patrones dentro de estas clasificaciones sin la necesidad de generar balanceos pesados que pueden llevarlo a sobre ajustes y pueda identificarlas muchísimo mejor y así eliminar este sesgo."
   ],
   "id": "31064f8d55c9a8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "22bdd46abb28ef6f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
